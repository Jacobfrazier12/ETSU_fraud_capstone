# Overview  

- This is a credit card fraud detection system that is written in Python.

- Out of curiosity, I began to wonder if I could take two unrelated credit card datasets and use them to create a fraud detection system.
- The first dataset was synthetically generated by the [Sparkov Data Generation Tool](https://github.com/namebrandon/Sparkov_Data_Generation.git).

- The second dataset is [hosted on Kaggle](https://www.kaggle.com/datasets/dhanushnarayananr/credit-card-fraud). 

- Because the Sparkov data is randomly generated, the results varied, sometimes being outstanding and at other times, less than ideal. 

# License

**You are free to distribute, copy, or modify this software, with or without credit towards the author; however, the author bares no responsibility for any damages sustained while using this software. Also, the software is offered "as-is."**

# Models used:
- Stochastic Gradient Decent
- Gaussian Naive Bayes
- Multi-nomial Naive Bayes
- K-Nearest Neighbor
- Nearest Centroid
- Random Forest
- Logistic Regression
- Logistic Regression CV
- Decision Tree

# Approach 

Since neither dataset contains columns similar to one another, I implemented an Extract, Transform, and Load (ETL) process.

After running the Sparkov tool, I extracted all the records, which were spread out across multiple files, into a single-unified CSV file.

I then began transforming the unified Sparkov data, so it would match the Kaggle dataset. Upon completion, the datasets conformed to the following schema:
   - distance from home:
      To calculate distance from home, I used the Haversine formula, which calculates the distance between two positional-coordinates.
   - distance from last transaction:
      To calculate distance from last transaction, I took the difference between distance from home for the current and previous transactions.
   - ratio to median purchase price:
      To calculated ratio to median purchase price, I divided the purchase amount by the median purchase amount for that user. 
   - used chip:
      to populate the used chip field, I checked the purchase category and operated under assumption that all transactions, excluding online and petrol station transactions, were done using the EMV chips. While this assumption isn't always true, it was the best approach given the lack of available information to infer the value with absolute-certainty. 
   - used pin number:
      To populate the used pin number field, I defaulted the value to 0 because, while, PIN-based credit cards do exist, I couldn't find evidence that they were widely available. 
   - online order:
      To populate the online order field, I checked the purchase category to infer the value.
   - repeat retailer:
      To populate the repeat retailer field, I checked the previous transaction's merchant to infer the value.
   - fraud:
      This field was already populated.

Now that I had the fields populated, I Scaled the distance from home/last transaction fields. This was done because the values present in these fields had a a high value-range, which caused issues with the machine-learning models. I also needed to take a sample of non-fraudulent transactions so that there would be an equal amount of non-fraudulent and fraudulent transactions. This was done to ensure the models were not biased towards non-fraudulent transactions.

# Results
   The results varied because the training data was randomly generated. Because of this, if you run this, you likely won't achieve the same results.




# Running the software
1. Ensure you have Python 3, Pip 3, and GNU Make installed.

2. Run `make init` && `make run`

- `make init` will install all required dependencies, via Pip; clone the Sparkov tool; and download the Kaggle dataset from Google Drive.

- `make run` will generate roughly half-a-gigabyte of data and train each model on said data. After each model is trained, it is tested against the second dataset. Two tests are performed: one against all non-fraudulent transactions and all fraudulent.

# Results at a glance

The results varied because the training data was randomly generated. Because of this, if you run this, you likely won't achieve the same results.


1. Model: Multinomial Naive Bayes
   all non-fraudulent: 91%
   all fraudulent: 57%

2. Model: K-nearest Neighbors 
   all non-fraudulent: 74%
   all fraudulent: 64%

3. Model: Random Forest 
   all non-fraudulent: 95%
   all fraudulent: 54%

4. Model: Logistic Regression 
   all non-fraudulent: 89%
   all fraudulent: 69%

5. Model: Logistic Regression CV 
   all non-fraudulent: 95%
   all fraudulent: 74%

6. Model: Neural Network
   all non-fraudulent: 94%
   all fraudulent: 66%